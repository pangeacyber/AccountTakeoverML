{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enriching Authentication data for ML based suspicious login detection\n",
    "\n",
    "Below we gather authentication information. We are pulling from a Pangea Audit log. From there we enrich the authentication information with Pangea User Intel and IP intel. Additional Python modules are used to extract features from included information. Specifically we look up an ASN number for IP. \n",
    "\n",
    "To save on IP and User intel lookup fees, we cache the results into json files for later re-use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from ipwhois import IPWhois\n",
    "\n",
    "current_directory = Path.cwd()\n",
    "parent_dir = current_directory.parent\n",
    "modules_dir = str(parent_dir.joinpath('modules'))\n",
    "sys.path.append(modules_dir)\n",
    "\n",
    "import pservices as Pangea_Services\n",
    "from vaultids import *\n",
    "\n",
    "pservices = Pangea_Services.pservices(url=\"aws.us.pangea.cloud\", VAULT_TOKEN=env_vault_token)\n",
    "\n",
    "if Path('ipcache.json').exists():\n",
    "    print(\"ip cache file exists\")\n",
    "    with Path('ipcache.json').open() as file:\n",
    "        ipcache = json.load(file)\n",
    "else:\n",
    "    ipcache = {}\n",
    "\n",
    "if Path('user.json').exists():\n",
    "    print(\"user cache file exists\")\n",
    "    with Path('user.json').open() as file:\n",
    "        usercache = json.load(file)\n",
    "else:\n",
    "    usercache = {}\n",
    "\n",
    "def add_user_intel(email_addr: str):\n",
    "    # This just returns 1/0 if breached or not.\n",
    "    if email_addr in usercache:\n",
    "        print(f\"------>> email address {email_addr} found in cache!!!\")\n",
    "        user_enrich = usercache[email_addr]\n",
    "        print(user_enrich)\n",
    "    else:\n",
    "        user_enrich = pservices.get_user_intel(email_addr)\n",
    "        #add to cache\n",
    "        usercache[email_addr] = user_enrich\n",
    "    return user_enrich\n",
    "\n",
    "def add_ip_intel(IP_addr: str):\n",
    "    # Check if the IP address is already in the cache\n",
    "    if IP_addr in ipcache:\n",
    "        print(f\"IP address {IP_addr} found in cache!!!\")\n",
    "        ip_enrich = ipcache[IP_addr]\n",
    "        print(ip_enrich)\n",
    "    else:\n",
    "        ip_enrich = pservices.ip_intel(IP_addr)\n",
    "\n",
    "        # Get the IP address location\n",
    "        print(f\"IP address NOT {IP_addr} found in cache!!!\")\n",
    "        print (ip_enrich['geo_location'])\n",
    "        ## sample output\n",
    "        # Country: Republic Of The Philippines, City: manila, Latitude: 14.59, Longitude: 121.0\n",
    "        # Country: French Republic, City: roubaix, Latitude: 50.69, Longitude: 3.17\n",
    "        match = re.search(r'Country: ([^,]+), City: ([^,]+), Latitude: ([\\d.-]+), Longitude: ([\\d.-]+)', ip_enrich['geo_location'])\n",
    "        if match:\n",
    "            country = match.group(1)\n",
    "            city = match.group(2)\n",
    "            latitude = float(match.group(3))\n",
    "            longitude = float(match.group(4))\n",
    "            print(f\"Country: {country}, City: {city}, Latitude: {latitude}, Longitude: {longitude}\")\n",
    "        else:\n",
    "            latitude = None\n",
    "            longitude = None\n",
    "            city = None\n",
    "            country = None\n",
    "\n",
    "        ip_enrich['asn'] = get_asn(IP_addr)\n",
    "        ip_enrich['latitude'] = latitude\n",
    "        ip_enrich['longitude'] = longitude\n",
    "        ip_enrich['city'] = city\n",
    "        ip_enrich['country'] = country\n",
    "\n",
    "        #add to cache\n",
    "        ipcache[IP_addr] = ip_enrich\n",
    "\n",
    "    return pd.Series(ip_enrich)\n",
    "\n",
    "def get_asn(ip: str):\n",
    "    if not ipaddress.ip_address(ip).is_private:\n",
    "        obj = IPWhois(ip)\n",
    "        res = obj.lookup_rdap(depth=1)\n",
    "        if res is not None:\n",
    "            return res['asn']\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "list = pservices.get_PangeaAuthLogs(maxresults=500)\n",
    "print (f\"Count of list: {len(list)}\")\n",
    "\n",
    "log_data = []\n",
    "for row in list:\n",
    "    print(row)\n",
    "    dict = row['external_context']\n",
    "    json_dict = json.loads(dict)\n",
    "    print (f\"user email - actor {json_dict['actor']['username']}\")\n",
    "    #print (f\"org id is {row['source']}\")\n",
    "    print (f\"Login time {row['timestamp']}\")\n",
    "    print (f\"login IP {json_dict['request']['ip']}\")\n",
    "    print (f\"User Agent {json_dict['client']['user_agent']}\")\n",
    "    print (f\"User id {json_dict['actor']['user_id']}\")\n",
    "\n",
    "    enriched = add_ip_intel(json_dict['request']['ip'])\n",
    "    breached_account = add_user_intel(json_dict['actor']['username'])\n",
    "\n",
    "    log_data.append({\n",
    "        'ip': json_dict['request']['ip'],\n",
    "        'useremail': json_dict['actor']['username'],\n",
    "        'userid': json_dict['actor']['user_id'],\n",
    "        'login_date': row['timestamp'],\n",
    "        'user_agent': json_dict['client']['user_agent'],\n",
    "        'latitude': enriched['latitude'],\n",
    "        'longitude': enriched['longitude'],\n",
    "        'country': enriched['country'],\n",
    "        'city': enriched['city'],\n",
    "        'breached': breached_account,\n",
    "        'org': row['source'],\n",
    "        'proxy': enriched['proxy'],\n",
    "        'vpn': enriched['vpn'],\n",
    "        'malicious': enriched['ip'],\n",
    "        'asn': enriched['asn'],\n",
    "    })\n",
    "\n",
    "print(log_data)\n",
    "\n",
    "with Path('ipcache.json').open('w') as file:\n",
    "    json.dump(ipcache, file)\n",
    "\n",
    "with Path('user.json').open('w') as file:\n",
    "    json.dump(usercache, file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a sanitized sample of our data\n",
    "\n",
    "- We have user email, IP, the useragent, login timestamp, a user id and an org id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 15)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "df = pd.DataFrame(log_data)\n",
    "\n",
    "def sanitize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    sanitized_df = df\n",
    "    sanitized_df['ip'] = sanitized_df['ip'].apply(lambda ip: ip.split('.')[0] + '.*.*.*')\n",
    "    sanitized_df['useremail'] = \"asdf@1234.com\"\n",
    "    sanitized_df['org'] = sanitized_df['org'].apply(lambda x: hash(x) % (10 ** 8))\n",
    "    sanitized_df['userid'] = sanitized_df['userid'].apply(lambda x: hash(x) % (10 ** 8))\n",
    "    sanitized_df['asn'] = sanitized_df['asn'].apply(lambda x: int(x) + 123)\n",
    "    return sanitized_df\n",
    "\n",
    "sanitized_df = sanitize(pd.DataFrame(log_data)) ## sanitize data for example purposes\n",
    "print (sanitized_df[['useremail','ip','user_agent','login_date','userid','org']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple report on IP and Breached users\n",
    "\n",
    "- Not super useful because there isn't context or comparison. \n",
    "- some users may always use a proxy or vpn \n",
    "- user are flagged as breached fairly regularly, doesn't mean the auth is a compromised on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 15)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "df = pd.DataFrame(log_data)\n",
    "\n",
    "sanitized_df = df\n",
    "sanitized_df['ip'] = sanitized_df['ip'].apply(lambda ip: ip.split('.')[0] + '.*.*.*')\n",
    "sanitized_df['useremail'] = \"asdf@1234.com\"\n",
    "sanitized_df['org'] = sanitized_df['userid'].apply(lambda x: hash(x) % (10 ** 8))\n",
    "sanitized_df['userid'] = sanitized_df['userid'].apply(lambda x: hash(x) % (10 ** 8))\n",
    "sanitized_df['asn'] = sanitized_df['asn'].apply(lambda x: int(x) + 123)\n",
    "\n",
    "print(sanitized_df.head(5))\n",
    "print(sanitized_df.shape)\n",
    "\n",
    "print(\"Authentications from Malicious IPs\")\n",
    "print(sanitized_df[sanitized_df['malicious'] != \"Safe\"])\n",
    "\n",
    "print(\"Authentications with Breached users\")\n",
    "print(sanitized_df[sanitized_df['breached'] == \"True\"])\n",
    "\n",
    "print(\"Authentications using VPN\")\n",
    "print(sanitized_df[sanitized_df['vpn'] == \"Yes\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covert enriched data to something a ML model can use\n",
    "\n",
    "- numeric values! \n",
    " numeric hashes\n",
    " booleans and true/false to 0/1\n",
    " label encoder for strings like OS and browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from user_agents import parse\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "df = pd.DataFrame(log_data)\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "df['login_date'] = pd.to_datetime(df['login_date'])\n",
    "df['hour_of_day'] = df['login_date'].dt.hour\n",
    "df['day_of_week'] = df['login_date'].dt.weekday\n",
    "df['ip_octets_sum'] = df['ip'].str.split('.').apply(lambda x: sum(map(int, x[:3])))\n",
    "df['user_agent_id'] = df['user_agent'].apply(lambda x: hash(x) % (10 ** 8))\n",
    "df['lat_long'] = df['latitude'] + df['longitude']\n",
    "df['breached'] = df['breached'].astype(int)\n",
    "df['proxy'] = df['proxy'].map({'Yes': 1, 'No': 0})\n",
    "df['vpn'] = df['vpn'].map({'Yes': 1, 'No': 0})\n",
    "df['malicious'] = df['malicious'].map({'Malicious': 1, 'Safe': 0})\n",
    "df['user_agent_browser_string'] = df['user_agent'].apply(lambda x: parse(x).browser.family if not \"\" else \"unknown\")\n",
    "df['user_agent_browser'] = encoder.fit_transform(df['user_agent_browser_string'])\n",
    "df['user_agent_browser_version_string'] = df['user_agent'].apply(lambda x: parse(x).browser.version_string if not \"\" else \"unknown\")\n",
    "df['user_agent_browser_version'] = encoder.fit_transform(df['user_agent_browser_version_string'])\n",
    "df['user_agent_os_string'] = df['user_agent'].apply(lambda x: parse(x).os.family if not \"\" else \"unknown\")\n",
    "df['user_agent_os'] = encoder.fit_transform(df['user_agent_os_string'])\n",
    "df['user_agent_os_version_string'] = df['user_agent'].apply(lambda x: parse(x).os.version_string if not \"\" else \"unknown\")\n",
    "df['user_agent_os_version'] = encoder.fit_transform(df['user_agent_os_version_string'])\n",
    "\n",
    "feature_columns = ['hour_of_day', 'day_of_week', 'ip_octets_sum', 'user_agent_id', 'lat_long', 'latitude', 'longitude', 'breached', 'proxy', 'vpn', 'malicious', 'user_agent_browser', 'user_agent_browser_version', 'user_agent_os', 'user_agent_os_version', 'asn']\n",
    "\n",
    "print (f\"sample df {df[feature_columns].sample(1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for nulls - these don't work in ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = df[df.isnull().any(axis=1)]\n",
    "print(nan_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a isolation forest machine learning model. \n",
    "\n",
    "contamination can be tuned to match your data. for instance .05 assumes that 5% of your data is bad/contaminated. \n",
    "\n",
    "We build this model on data older that 1 day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "model = IsolationForest(n_estimators=1000, contamination=0.01, random_state=0, max_samples='auto')\n",
    "model.fit(df[df['login_date'] < datetime.now(pytz.utc) - timedelta(days=1)][feature_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an outlier detection on data greater than one day old. \n",
    "The shap module helps explain why the particular record was found to be an outlier. If no outliers were found in your data, play with the contamination variable above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(model)\n",
    "\n",
    "for _index, row in df[df['login_date'] > datetime.now(pytz.utc) - timedelta(days=1)].iterrows():\n",
    "    this_df = pd.DataFrame(row).transpose()\n",
    "    prediction = model.predict(this_df[feature_columns])\n",
    "    if (prediction == -1):\n",
    "        print(f\"Anomaly detected !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        shap_values = explainer(this_df[feature_columns])\n",
    "        shap.plots.waterfall(shap_values[0])\n",
    "        print(f\"source data {this_df.transpose()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codetesting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
